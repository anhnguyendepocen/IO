---
title: "Untitled"
author: "Christopher Hayes, David Hakula, Filip Mellgren"
date: '2019-04-13'
output:
  html_document:
    code_folding: hide
    df_print: kable
    highlight: zenburn
    theme: readable
---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r cars, include = FALSE}
library(rio)
library(tidyverse)
library(AER)
library(ggthemes)
library(stargazer)
library(reshape2)
library(xtable)
#library(plm)
library(glue)
library(zoo)
```
# Step 0
```{r}
df <- import("Cars.dta")
df <- df %>% mutate(yearcountry = paste(year, country),
                    i = 1)
df <- df %>% group_by(country) %>% mutate(agg.cty.yr.qu = sum(qu),
                                              N = sum(i)) %>% ungroup()

df <- df %>% mutate(qw = qu / (agg.cty.yr.qu/N)) %>% as_tibble()
df <- df %>% mutate(wdomestic = domestic * qw,
                    wfuel = fuel * qw,
                    whorsepower = horsepower * qw,
                    wweight = weight * qw,
                    wwidth = width * qw,
                    wheight = height * qw,
                    wpr = pr * qw,
                    wprice = price * qw,
                    wprinc = princ * qw,
                    wsegment = segment * qw)


df %>% glimpse()
```

# 1 Summary statistics
Show and discuss summary statistics of the car market in the five EU countries. Focus on what you believe are key variables given the questions at hand.

Could be the case: "Note that the panel is unbalanced because most models are not available throughout the entire period or in all countries."
```{r}
# Create two functions that are used throughout the analysis to create 
# descriptive tables

# TODO: Add necessary summary stats. Do we need percentiles?
summary_stats <- function(x){
  x <- as.matrix(x)
  
  summary <- rbind(mean(x, na.rm = TRUE), sd(x, na.rm = TRUE)/sqrt(nrow(x)), min(x, na.rm = TRUE), 
                   max(x, na.rm = TRUE))
    return(summary)
}

# Takes above and turns it into a nice table
summary_table<- function(summary){
  summary <- as_tibble(summary) %>% t() %>% round(2) %>% as_tibble(rownames = "Variable") %>% rename ("Mean" = V1, "S.e." = V2, "Min." = V3, "Max." = V4)
  return(summary)
}
```


```{r}
# Summary statistics to Q1.
descriptive_table <- df %>%
  select(country, wdomestic, qu, wprice, wprinc, wsegment, wweight, wwidth, wheight, whorsepower, wfuel,  pop, year) %>% 
  mutate(pop = pop/1000000) %>%
  map(function(x) summary_stats(x)) %>% summary_table() %>% mutate(country = "All")

for (c in 1:5) {
 descriptive_table <-  rbind(descriptive_table, df %>% filter(country == c) %>% 
  select(country, wdomestic, qu, wprice, wprinc, wsegment, wweight, wwidth, wheight, whorsepower, wfuel,  pop, year) %>% 
    mutate(pop = pop/1000000) %>%
  map(function(x) summary_stats(x)) %>% summary_table() %>% mutate(country = c))
}



tmp_table <- descriptive_table %>% arrange(Variable) %>% 
  mutate("se" = paste(S.e., ")", sep = ""),
    "Mean_se" = paste(Mean, se, sep = " (")) %>% 
  select(Variable, Mean_se, country) %>% # Add min and max later for simplicity
  spread(key = country, value = Mean_se)

tmp_table <- rbind(tmp_table, tmp_table) %>% arrange(Variable) %>% 
  filter(Variable != "country") %>% 
  select(Variable, All, "1", "2", "3", "4", "5") %>% rename("Belgium" = "1", 
                                                            "France" = "2",
                                                            "Germany" = "3",
                                                            "Italy" = "4",
                                                            "UK" = "5")

tmp_table_means <- tmp_table[seq(1, nrow(tmp_table), 2), ] %>% mutate(All = word(All,1),
                                                   Belgium = word(Belgium),
                                                   France = word(France,1),
                                                   Germany = word(Germany,1),
                                                   Italy = word(Italy,1),
                                                   UK = word(UK,1))

tmp_table_se <- tmp_table[seq(1, nrow(tmp_table), 2), ] %>% mutate(All = word(All,2),
                                                   Belgium = word(Belgium,2),
                                                   France = word(France,2),
                                                   Germany = word(Germany,2),
                                                   Italy = word(Italy,2),
                                                   UK = word(UK,2))
# Create a table for the mins and maxes
minmax_table <- df %>%
  select(country, domestic, qu, price, princ, segment, weight, width, height, horsepower, fuel,  pop, year) %>% 
  mutate(pop = pop/1000000) %>%
  map(function(x) summary_stats(x)) %>% summary_table() %>% 
  select(Variable, Min., Max.) %>% filter(Variable != "country")

                                                   
Table_1 <- rbind(tmp_table_means, tmp_table_se) %>% full_join(minmax_table) %>% arrange(Variable) %>% 
  select(Variable, All, Min., Max., Belgium, France, Germany, Italy, UK)

xtable(Table_1)
```
Table 1 shows summary statistics for the five EU countries at a country level and at a European level. Perhaps the most interesting finding is that the average price of cars in the UK is well above the European average, at 24.4 compared to 18.5. We note that the average car sold in the UK is not drastically different from its European counterparts when it comes to physical attributes of the car, which makes the finding hard to rationalise. However, a potential explanation could be higher costs associated with the policy of driving on the right side of the road.


```{r}
# Correlation matrix to Q1.
# Strictly necessary?
cormatdf <- df %>% select(price, qu, year, domestic, horsepower, fuel, weight)
cormat <- round(cor(cormatdf),2)

melted_cormat <- melt(cormat)

melted_cormat %>% ggplot(aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + theme_economist() + scale_colour_economist() +
  labs( y = " ", x = " ", tag = "Graph 1") +
  scale_fill_gradient2(low = "#336666", high = "#664033", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  geom_text(aes(Var1, Var2, label = value), color = "black", size = 4)
```

```{r}
ggsave("cormat.png", height = 15, width = 17, units = "cm")
```

Excluded co (model code), segment (ordinal variable), firm, country, because they are nonsensical
Also height and width were excluded, because they were not deemed as important
Pop was excluded because it is not a feature related to the cars

Discuss the difference in prices across countries. Look at UK mean prices for example.

Tendency to buy domestic cars

Mention the data set that we have access to (briefly)

# 2 Hedonic price regression

Table 2 shows a price regression with car characteristics as explanatory variables. Attributes that seem to be associated with a highe rcar price include horsepower and the width, reflecting that larger more powerful cars are more expensive.  

We note that over the period, cars seem to have got less expensive, averaging at minus 1 percent per year according to the most elaborated specification with car model fixed effects.

```{r}
# TODO: add the correct variables to X
# TODO: Squeeze the latex table
# TODO: Add segment dummies?

X <- glue("year", "horsepower", "fuel", "width", "weight", "height", "domestic", "year", 
          "country1", "country2", "country3", "country4", .sep = "+")

formula <- glue("log(price) ~", X)
lm.fit <- lm(formula, data = df)

```
```{r}
fe_formula <- glue("log(price) ~", X, "factor(co)", .sep = "+")
fe.fit <- lm(fe_formula, data = df)

# Create table 2 further down
```


# 3 Market shares

Calculate the following market shares: (a) the market share of each
car model, and (b) the market share of each car model in its segment.
Discuss your findings. Assume that the total market size is the number
of households, approximated by total population divided by 4

Comment: "In practice, the potential market size in a given year may be lower because cars are durable and consumers who just purchased a car may not consider buying a new one
immediately."

Our assumptions about market structure and consumer options enable us to empirically estimate the deterministic component of utility $\delta_j$ from any inside good $j$ as a function of its market share $s_j$ relative to that of the outside good (both observable variables).

Most crucial is our multinomial logit assumption concerning the distribution of the structural error in the utility function ($\varepsilon_{i0},...,\varepsilon_{iJ}$), which we assume to be type 1 extreme value distributed. 

$s_j = \frac{q_j}{\sum_{h=1}^{J}q_h} = \frac{N*P_{ij}}{N}=P_{ij} = P\{\varepsilon_{i0},...,\varepsilon_{iJ}: u^{*}_{ij}>u^{*}_{ik}$ for $j\neq k\} \underbrace{=}_{\because\text{ multinomial logit}} \frac{exp(\delta_{ij})}{\sum_{h=0}^{J}exp(\delta_{ih})}$

Taking logs:
$\delta_{j} = log(s_j) + log(\underbrace{\sum_{h=0}^{J}exp(\delta_{ih})}_{\delta_0=0 \Rightarrow exp(\delta_0)=1}) = log(s_j) + \underbrace{log(1 + \sum_{h=1}^{J}exp(\delta_{ih}))}_{=-log(s_0) \text{ } \because \text{ } \delta_0=0} = log(s_j) - log(s_0)$ 

In specific market $m$:
$\delta_{jm} = log(s_{jm}) - log(s_{0m}) = X'_{jm}\beta - \alpha p_{jm} + \xi_{jm} = X'_{jm}\beta - \alpha p_{jm} + \underbrace{\xi_j + \xi_m}_\text{fixed effects} + \eta_{jm}$


```{r}
# TODO: maybe take the five highest and five lowest per a and b. Most popular cars and least popular car

#a
df <- df %>% mutate(msize = pop/4, 
              mshare = qu/msize,
              ln_mshare = log(mshare))
# b
df <- df %>% group_by(segment, yearcountry) %>% mutate(tot_s = sum(qu)) %>%
  ungroup()
df <- df %>% mutate(mshare_s = qu / tot_s,
                    ln_mshare_s = log(mshare_s))

# Table 1
Table_3 <- df %>% mutate(mshare = mshare *100,
              mshare_s = mshare_s *100) %>% 
  select(mshare, mshare_s, ln_mshare, ln_mshare_s) %>% 
  map(function(x) summary_stats(x)) %>% summary_table()

xtable(Table_3)

# market shares by firm over year, car models and countries
# Likely not necessary
df %>% group_by(firm) %>% summarise(mean = mean(mshare)*100, se = sd(mshare*100),
                                    min = min(mshare*100), max = max(mshare*100))

```
To begin with, the market share of each car model is low, averaging at 0.16%, and no car model ever had a higher overal market share than the Fiat Uno, which in Italy 1986 held a 3.03% market share. Among the 24 observations where a market share above 2.5% were observed, 14 were Fiats sold in Italy. Another 7 were VW sold in Germany, and 2 were Renaults sold in France. These anecdotes reflect a broader pattern of car models being more popular in their country of origin, as noticed in the correlation between country and domestic (0.59).

In the respecitve segments, market shares tend to be much higher, averaging at 6.5% rather than 0.16%, and some markets experience extreme concentration within segments, as hinted by the maximum segment share observed being 100%. 

We further investigated where extreme segment market shares are observed and found that the luxury segment is more often dominated by a few models. Notably, out of 91 models that experienced a market shares above 50%, 63 (69%) were in the luxury segment, and of the 626 models with at least 25% market share, 214 (34%) were in the luxury segment. 

Overall, we expect segments to be important in the analysis as we expect consumers to be less likely to switch to car models between segments as a result of price changes on one model in a segment. This leaves room for market power as concentration within segments is typically higher, particularly in the luxury segment.

# 4 Logit demand
Supposed to pool the data?

Estimate demand using a logit specification (Berry, 1994). Use different estimators such as OLS and fixed effects. Use your estimated
coefficients to calculate own-price elasticities. Interpret your results.
Are there any interesting differences across firms?


```{r}
df <- df %>% group_by(yearcountry) %>% mutate(tot_qu = sum(qu),
                                        oshare = 1 - tot_qu/msize) %>% ungroup()

df <- df %>% mutate(ln_dmshare = log(mshare) - log(oshare))
```

```{r}
# Adds price to the X
X <- glue("price", "year", "horsepower", "fuel","weight", "width","height", "domestic", "year",
          "country1", "country2", "country3", "country4", .sep = "+")
X_fe <- glue(X, "factor(co)", .sep = "+")

formula <- glue("ln_dmshare ~", X)
fe_formula <- glue("ln_dmshare ~", X_fe, "factor(co)", .sep = "+")
lm.logit <- lm(formula, data = df)
fe.logit <- lm(fe_formula, data = df)

# TODO: do we present this or is it enough with the elasticities?
#stargazer(lm.logit, fe.logit, type = "text", omit = "factor")
```

```{r}
# TODO: what coefficient do we use to estimate the elasticities? Maybe both
alpha_1 <- lm.logit[["coefficients"]][["price"]]
df <- df %>% mutate(own_price_elasticity = alpha_1 * (1 - mshare)*price)

summary_stats(df$own_price_elasticity) %>% summary_table()
```

```{r}
# What's this good for?
df <- df %>% group_by(firm) %>% mutate(avg_e_jj_l = mean(own_price_elasticity)) %>% ungroup()

#df <- fastDummies::dummy_cols(df, select_columns = "firm")


```


# 5 Nested logit demand
Estimate demand using a nested logit specification where segment is
defined as the nest (Berry, 1994). Use different estimators such as OLS
and fixed effects. Use your estimated coefficients to calculate own-price
elasticities. Discuss your results.

```{r}
df <- df %>% mutate(ln_mshare_s = log(mshare_s))


# Adds ln_mshare_s to the X
X <- glue("price", "year", "horsepower", "fuel","weight", "width","height", "domestic", 
          "year", "ln_mshare_s","country1", "country2", "country3", "country4", .sep = "+")
X_fe <- glue(X, "factor(co)", .sep = "+")

formula <- glue("ln_dmshare ~", X)
lm.nest <- lm(formula, data = df)
fe_formula <- glue("ln_dmshare ~", X_fe)
fe.nest <- lm(fe_formula, data = df)
```

```{r}
alpha_1 <- lm.logit[["coefficients"]][["price"]]


alpha_2 <- lm.nest[["coefficients"]][["price"]]
sigma <- lm.nest[["coefficients"]][["ln_mshare_s"]]

alpha_1_fe <- fe.logit[["coefficients"]][["price"]]
df <- df %>% mutate(own_price_elasticity = alpha_1 * (1 - mshare)*price)

alpha_2_fe <- fe.nest[["coefficients"]][["price"]]
sigma_fe <- fe.nest[["coefficients"]][["ln_mshare_s"]]

df <- df %>% mutate(own_price_elasticity = alpha_1 * (1 - mshare)*price)
df <- df %>% mutate(e_jj_nl = alpha_2 * (1/(1-sigma) - (sigma/(1-sigma)) * mshare_s  - mshare)*price)
df <- df %>% mutate(own_price_elasticity_fe = alpha_1_fe * (1 - mshare)*price)
df <- df %>% mutate(e_jj_nl_fe = alpha_2_fe * (1/(1-sigma_fe) - (sigma_fe/(1-sigma_fe)) * mshare_s  - mshare)*price)



Table_4 <- df %>% 
  select(own_price_elasticity, own_price_elasticity_fe, e_jj_nl,e_jj_nl_fe) %>%
  map(function(x) summary_stats(x)) %>% summary_table()

xtable(Table_4, caption = "Aggregated elasticity estimates")
```

```{r}
Table2 <- stargazer(lm.fit, fe.fit, lm.logit, fe.logit, lm.nest, fe.nest, omit = "factor", column.sep.width = "2pt", font.size = "footnotesize", omit.stat = "f")
```


```{r}
# Calculates average average elasticity within nest for each firm
df <- df %>% group_by(firm) %>% mutate(avg_e_jj_nl = mean(e_jj_nl)) %>% ungroup()
```


```{r}

Figure_data <- df %>% rename("Baseline" = own_price_elasticity, "Model F.E" = own_price_elasticity_fe) %>% gather(key = "Specification", value = "value", Baseline, "Model F.E") %>% group_by(firm, Specification) %>% summarise("mean_el" = abs(mean(value)), "se" = sd(value)/sqrt(n()))


  Figure_data %>% ggplot(aes(x = as.factor(reorder(firm, -mean_el)), y = mean_el, fill = Specification)) +
  geom_bar(stat="identity", position = "dodge")  +
  theme_economist() + scale_fill_manual(values = alpha(c("#336666", "#8abbd0"), 1)) +
  labs(title = "Logit absolute elasticities", 
       y = "(Absolute) Elasticities", x = "Firm ID", tag = "Graph 2",
       caption = "Baseline corresponds to estimates from column 5, Table 2, Model.F.E. corresponds to column 6. 
       Error bars show 95% CI.") + 
    geom_errorbar(aes(ymin=mean_el-2*se, ymax=mean_el +2*se), width=.2,
                 position=position_dodge(.9))
```
```{r}
ggsave("elast.png", height = 16, width = 20, units = "cm")

```


# 6 Instruments

Goldberg, Verboven 2001 section 4.2 provides some insight: variables that shift the producers' supply relations, but are excluded from the demand equations, make natural instruments
 
 
Suggest two types of instruments that could be used to solve the endogeneity problem of the price variable. Why do you propose these instruments?

Want to find something that shifts the supply curve:
Things that change the marginal cost:

* price on car paint
* Strikes specific to the car industry or where strike wage remains. 

To solve the endogeneity problem of the price variable, we need instruments that shifts the supply in market, without affecting the demand.

As a first instrument, we suggest price on car paint. This clearly affects the price through the supply side, by increasing the marginal costs of the supplier. The price on car paint hence should be relevant (note that this is testable, given data on price of car paint). It is unlikely that the price on car paint affects the market price through any channel on the demand (or any other channel for that matter) and hence it is likely that the instrument would also be valid. 

Furthermore, we suggest to use data on strikes specific to the car industry. This should increase the production costs and hence shift supply, making the instrument relevant (not again that this is testable, given access to data). The validity of the instrument relies on the assumption that the strike does not affect the strikers demand for cars in such a way that total market demand is affected. We deem the validity as likely: the total population share working in the car industry is usually rather low on a national level. Also, strike funds are often utilized during strikes to compensate strikers for the absent wages. 


# 7 Nash Bertrand
Assume Nash-Bertrand competition in prices on the supply side. Calculate the implied marginal costs, markups and Lerner index based on the estimates from the nested logit specification in [5]. Present firmlevel averages of price, marginal cost, markup and the Lerner index.

Do you think your results are economically meaningful? Explain and discuss.

```{r}
# TODO: Note that markups are negative
# markups
df <- df %>% mutate(pderiv = alpha_2_fe * mshare*((1/(1-sigma_fe))-(sigma_fe/(1-sigma_fe))*mshare_s-mshare),
                    markup = -mshare/pderiv, # "-" to get the right sign
                    mc = price - markup,
                    lerner = markup/price)
# TODO: what is markup2? 

# summarise

```
```{r}
# firm level averages (pre merger)
df <- df %>% group_by(firm) %>% mutate(avg_markup = mean(markup),
                                 avg_mc = mean(mc),
                                 avg_lerner = mean(lerner),
                                 avg_price = mean(price)) %>% ungroup()

# Table for question 7. Pre merger descriptives. Table_5
pricing_table <- df %>% select(firm, avg_price, avg_mc, avg_markup, avg_lerner) %>% 
  distinct(firm, .keep_all = TRUE) %>% arrange(-avg_price)
Table_5 <- pricing_table


```
Table X present firm level averages, ranked by average price. Apparently, the Lerner index is higher for low priced cars (the correlation between price and the lerner index is -82%). This finding can be justified when considering that prices observed are prices to consumers (in retail catalogues), not to car dealers which would be a better measure for the car manufacturers. We think the dealer would typically add something close to a constant fee per vehicle to cover her costs of selling it, absorbing most of the mark up observed for cheap cars, whereas larger cars with higher mark ups in absolute terms (correlation between markups and price is 17%) will still be able to maintain some markup after subtracting the fee. (Note to self: info about prices obtained form footnote 2 in Goldberg, Verboven 2001)

The results are obviously meaningful from an economic point of view insofar as the assumptions of the model hold. The average price is, as already discussed, the observed average price is what consumers paid for a car of a particular brand between 1970 and 1999 (in 1000s of euros in 1999 purchasing power), the marginal cost is the estimated marginal cost manufacturers face when producing the car model (in the same units) and the mark up is simply the difference between these. The average lerner index is the markups over price and a higher value indicate that a firm enjoys a higher market power, i.e. is either more efficient in production (cheaper marginal costs) or sells a product consumers are willing to pay a premium for. 

The lerner index has another economic meaning, namely that the absolute value of the inverse lerner is the price elasticity of demand facing each firm. Derivation?



# 8 Merger

```{r merger_function}
post_merger_df <- function(dataframe, ratio_mc){
  # this takes a data frame, creates new variables and returns the same data frame
  dataframe <- dataframe %>% 
    mutate(firmnew = if_else(firm == 15 & country == 3 & year >= 1998, 26, firm), 
           segment_new = if_else(co == 177 & country == 3 & year >= 1998, 4, segment), 
           qu_new = case_when( 
             co == 164 & country == 3 & year >= 1998 ~ qu*0.75, 
             co == 166 & country == 3 & year >= 1998 ~ qu*0.5, 
             co == 168 & country == 3 & year >= 1998 ~ 0, 
             TRUE ~ qu), 
           mshare1 = qu_new/msize)
  
dataframe <- dataframe %>% group_by(segment_new, yearcountry) %>% 
  mutate(tot_s1 = sum(qu_new), 
         mshare_s1 = qu_new / tot_s1) %>% ungroup()

# TODO: double check we should be using alpha_2 and not something else
dataframe <- dataframe %>% mutate(mc         = case_when(firm == 26 & country == 3 & year >= 1998 ~ mc * ratio_mc,
                                                         TRUE ~ mc),
                                  pderiv_new = alpha_2_fe * mshare1*((1/(1-sigma_fe))-(sigma_fe/(1-sigma_fe))*mshare_s1-mshare1),
                                  markup_new = -(mshare1 / pderiv_new),
                                  price_new  = mc + markup_new,
                                  lerner_new = markup_new / price_new,
                                  dprice     = price_new/price-1)

# By firm: avg_price, avg_mc, avg_markup, avg_lerner
dataframe <- dataframe %>% group_by(firm) %>% mutate(avg_markup_new = mean(markup_new),
                                 avg_mc_new = mean(mc),
                                 avg_lerner_new = mean(lerner_new),
                                 avg_price_new = mean(price_new, na.rm = TRUE)) %>% ungroup()

dataframe <- dataframe %>% group_by(firm) %>% mutate(AVG_markup_new = mean(markup_new[year == 1998]),
                                 AVG_mc_new = mean(mc[year == 1998]),
                                 AVG_lerner_new = mean(lerner_new[year == 1998]),
                                 AVG_price_new = mean(price_new[year == 1998], na.rm = TRUE)) %>% ungroup()


  return(dataframe)
}
```

```{r}
merger_df <- post_merger_df(df, 1)
```


```{r}
#merger_df %>% filter(year == 1998, country == 3) %>%
 # select(mshare_s, mshare_s1) %>% map(function(x) summary_stats(x)) %>% summary_table()
```
## Post merger


```{r}
merger_df <- merger_df %>% mutate(wprice_new = price_new * qw,
                                  wdprice = dprice * qw)
ger_table <- merger_df %>% filter(year == 1998, country == 3, !is.na(price_new)) %>% drop_na() %>% 
  select(price, price_new, dprice, wprice, wprice_new, wdprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name = "ger")

# GM
gm_table <- merger_df %>% filter(year == 1998, country == 3, firm == 15, !is.na(price_new)) %>% #drop_na() %>% 
  select(price, price_new, dprice, wprice, wprice_new, wdprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name = "gm")

# VW
vw_table <- merger_df %>% filter(year == 1998, country == 3, firm == 26, !is.na(price_new)) %>% drop_na() %>% 
  select(price, price_new, dprice, wprice, wprice_new, wdprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name ="vw")

# Segments
segment_price_change <- tibble()
for (s in 1:5) {
  segment_price_change <- 
    rbind(segment_price_change, merger_df %>% 
            filter(year == 1998, segment == s) %>% drop_na() %>% 
            select(price) %>% map(function(x) 
              summary_stats(x)) %>% summary_table() %>% cbind(name =glue("segment",s)),
          merger_df %>% 
            filter(year == 1998, segment_new == s) %>% drop_na() %>% 
            select(price_new) %>% map(function(x) 
              summary_stats(x)) %>% summary_table() %>% cbind(name =glue("segment",s)),
          merger_df %>% 
            filter(year == 1998, segment == s, segment_new == s) %>% drop_na() %>% 
            select(dprice) %>% map(function(x) 
              summary_stats(x)) %>% summary_table() %>% cbind(name =glue("segment",s)))
}


price_change_table <- rbind(ger_table, gm_table, vw_table, segment_price_change) %>% select(Variable, Mean, name) %>% spread(key = Variable, value = Mean) %>% select(-dprice) 

price_change_table # USed for graphs
```


Note that dprice does not correspond to (price_new - price) / price.

# 9 Efficient merger
Redo 8 with a changed mc. Tabulate all 5 segments.

```{r}
merger_df_9 <- post_merger_df(df, 0.8)
```

```{r}
merger_df_9 %>% filter(year == 1998, country == 3) %>% 
  select(mshare_s, mshare_s1) %>% map(function(x) summary_stats(x)) %>% summary_table()
```

```{r}
ger_table <- merger_df_9 %>% filter(year == 1998, country == 3) %>% drop_na() %>% 
  select(price, price_new, dprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name = "ger")

# GM
gm_table <- merger_df_9 %>% filter(year == 1998, country == 3, firm == 15) %>% # Can't drop_na()
  select(price, price_new, dprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name = "gm")

# VW
vw_table <- merger_df_9 %>% filter(year == 1998, country == 3, firm == 26) %>% drop_na() %>% 
  select(price, price_new, dprice) %>% map(function(x) summary_stats(x)) %>% summary_table() %>% cbind(name ="vw")

# Segments
segment_price_change2 <- tibble()
for (s in 1:5) {
  segment_price_change2 <- 
    rbind(segment_price_change2, merger_df_9 %>% 
            filter(year == 1998, segment == s) %>% drop_na() %>% 
            select(price, price_new, dprice) %>% map(function(x) 
              summary_stats(x)) %>% summary_table() %>% cbind(name =glue("segment",s)))
}




price_change_table_2 <- rbind(ger_table, gm_table, vw_table, segment_price_change2) %>% select(Variable, Mean, name) %>% 
  spread(key = Variable, value = Mean) %>% select(-dprice)

price_change_table_2 <- price_change_table_2 %>% rename(efficient_price = price_new)
```

# Table 5 related
```{r}
# Compare per-merger and post-merger prices: 
# combine with table from 7
pricing_table <- df %>% dplyr::select(firm, price, year) %>% group_by(firm)%>% mutate(AVG_price = mean(price[year == 1998])) %>% distinct(firm, .keep_all = TRUE) %>% ungroup() %>% select(-year)

pricing_table_new <- merger_df %>% select(firm, AVG_price_new) %>% 
  distinct(firm, .keep_all = TRUE)

pricing_table_new_eff <- merger_df_9 %>% rename(eff_price = AVG_price_new) %>% select(firm, eff_price) %>% distinct(firm, .keep_all = TRUE)

Table_5 <- full_join(pricing_table, pricing_table_new) %>% full_join(pricing_table_new_eff) %>% 
  mutate("Delta price (p.mille)" = 1000 * (avg_price_new/avg_price-1),
         "Delta price (efficient) (p.mille)"  = 1000 * (eff_price/avg_price-1)) %>%
  select(firm, avg_price, avg_price_new, eff_price, "Delta price (p.mille)", "Delta price (efficient) (p.mille)", everything()) %>% 
  rename("Pre price" = avg_price, "Post price" = avg_price_new) %>% 
  column_to_rownames(var = "firm") 

xtable(Table_5)
```


# graph related:
```{r}
# Merge the two price change tables
pre_post_table <- full_join(price_change_table, price_change_table_2)

pre_post_table <- pre_post_table %>% gather(price_type, price, -name) %>% 
  mutate(treatment = if_else(price_type == "price", 0, 1)) # WHy do we do this?
```


# 10 2 more features
We know what happens to production, but happens to sales?
What branding effects are there that might affect sales?

More nests?

The analysis conducted above focuses on the company level and production aspect of the merger. However, other important aspects of the businesses involved are likely to be affected as well. 

One aspect is sales and marketing. The car market is likely to be characterized by consumer loyalties, that perhaps is not captured in the product characteristics analysis made, above that could be affected by a merger: It is not curtain (as the above conducted analysis assumes) that the demand for a particular brand stays the same. E.g., some customers might value the “Americaness” and the American values that GM symbolizes. Such customers might be less willing to buy their models after a merger, where the GM production has been taken over by German Volkswagen. To the contrary, it could also create interesting co-branding opportunities. Such aspects of sales and marketing should hence also be considered in merger analysis. This could for example be done by incorporating these aspects into the model above, by scoring of these aspects of the products and estimation of how they would change with the merger through consumer surveys. 

Another aspect to be considered is the number of nests. We believe that a model using a richer variety of nests would more accurately capture the market behavior. [Filip: I don’t remember what we said here?]

Taxes varying across nation? or is it captured by country dummies?

# Graphs
```{r}
pre_post_table <- pre_post_table %>% select(-treatment) %>%  
  spread(price_type, price) 
```
```{r}
graph_table <- pre_post_table %>% filter(name %in% c("ger", "gm", "vw"))

graph_table %>%
  ggplot(aes(x = as.factor("Pre merger"), y = price)) +
  geom_segment(aes(xend = as.factor("Post merger"), yend = price_new,color = "#336666"),
               size = 0.8) +
  geom_segment(aes(xend = as.factor("Post merger"), yend = efficient_price, color = "#e3120b"), size = 0.8) +
  geom_point(size = 3) +
  geom_point(aes(x = as.factor("Post merger"),y = price_new), size = 3) +
  geom_point(aes(x = as.factor("Post merger"), y = efficient_price), size = 3) +
  theme_economist() + scale_fill_economist() + scale_color_economist() +
  annotate("text", x = 0.85, y = graph_table$price, label = as.character(graph_table$name)) +
  labs(title = "Merger effects on prices", y = "Average price",
       tag = "Graph 3") +
  scale_x_discrete(name ="", limits=c("Pre merger","Post merger")) +
  scale_colour_manual(guide = "legend", name = "Merger type:",
         values =c("#336666"="#336666","#e3120b"="#e3120b"), 
         labels = c("Not cost reducing","Cost reducing")) +
  theme(plot.tag.position = "bottom") +
  scale_y_continuous(limits=c(0, 40))

  
```
```{r}
ggsave("merger_causal_effect.png", height = 20, width = 12, units = "cm")
```

```{r}
# Graph above, but for segments. 

graph_table <- pre_post_table %>% filter(!name %in% c("ger", "gm", "vw"))

graph_table %>%
  ggplot(aes(x = as.factor("Pre merger"), y = price)) +
  geom_segment(aes(xend = as.factor("Post merger"), yend = price_new,color = "#336666"),
               size = 0.8) +
  geom_segment(aes(xend = as.factor("Post merger"), yend = efficient_price, color = "#e3120b"), size = 0.8) +
  geom_point(size = 3) +
  geom_point(aes(x = as.factor("Post merger"),y = price_new), size = 3) +
  geom_point(aes(x = as.factor("Post merger"), y = efficient_price), size = 3) +
  theme_economist() + scale_fill_economist() + scale_color_economist() +
  annotate("text", x = 0.8, y = graph_table$price, label = as.character(graph_table$name)) +
  labs(title = "Merger effects on prices", y = "Average price",
       tag = "Graph 4") +
  scale_x_discrete(name ="", limits=c("Pre merger","Post merger")) +
  scale_colour_manual(guide = "legend", name = "Merger type:",
         values =c("#336666"="#336666","#e3120b"="#e3120b"), 
         labels = c("Not cost reducing","Cost reducing")) +
  theme(plot.tag.position = "bottom") +
  scale_y_continuous(limits=c(0, 40))

  
  
```
```{r}
ggsave("merger_causal_effect_segment.png", height = 20, width = 12, units = "cm")
```

